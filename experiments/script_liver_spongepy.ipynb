{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import squidpy as sq\n",
    "from skimage import io\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from napari_spongepy import functions as fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data \n",
    "The first step of the analysis includes defining the paths to both the DAPI stained image and the list of the coordinates for each transcript. \n",
    "\n",
    "Afterwards, the image is read in, and is seen as a numpy array for the whole analysis.\n",
    "\n",
    "image is expected to be a tiff file, trancripts location a txt file. \n",
    "\n",
    "When working with both nucleus and cellwall images, both paths need to be defined here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name_slide = 'A1-1'\n",
    "path_Coordinates = '../data/resolve/20272_slide1_'+name_slide+'_results.txt'\n",
    "path_image = \"../data/resolve/20272_slide1_\"+name_slide+\"_DAPI.tiff\"\n",
    "img = io.imread(path_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the image(s)\n",
    "\n",
    "When working with RESOLVE data, the data is acquired in tiles, and the illumination within a tile isn't always constant. Sometimes one side of a tile is more illuminated than the other, influencing the downstream analysis greatly. RESOLVE assured us this isn't linked to the counts of the transcripts, but this can be checked further on.\n",
    "\n",
    "Basic is a tool that can correct for this, and is used in this functiosn, the size of a tile, 2144, is hardcoded, and used to defined the tile. \n",
    "\n",
    "If you don't see any tiling effects, this step might not be necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pybasic' has no attribute 'basic'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mc:\\Users\\Desplenter Koen\\Documents\\VIB\\napari-spongepy\\experiments\\script_liver.ipynb Cell 6\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Desplenter%20Koen/Documents/VIB/napari-spongepy/experiments/script_liver.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m img \u001B[39m=\u001B[39m fc\u001B[39m.\u001B[39;49mBasiCCorrection(img\u001B[39m=\u001B[39;49mimg)\n",
      "File \u001B[1;32m~\\Documents\\VIB\\napari-spongepy\\src\\napari_spongepy\\functions.py:36\u001B[0m, in \u001B[0;36mBasiCCorrection\u001B[1;34m(path_image, img)\u001B[0m\n\u001B[0;32m     34\u001B[0m         tiles\u001B[39m.\u001B[39mappend(temp)\n\u001B[0;32m     35\u001B[0m \u001B[39m# measure the filters\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m flatfield \u001B[39m=\u001B[39m pybasic\u001B[39m.\u001B[39;49mbasic(tiles, darkfield\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m, verbosity\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m)\n\u001B[0;32m     38\u001B[0m tiles_corrected \u001B[39m=\u001B[39m pybasic\u001B[39m.\u001B[39mcorrect_illumination(\n\u001B[0;32m     39\u001B[0m     images_list\u001B[39m=\u001B[39mtiles, flatfield\u001B[39m=\u001B[39mflatfield[\u001B[39m0\u001B[39m]\n\u001B[0;32m     40\u001B[0m )  \u001B[39m# darkfield = darkfield)\u001B[39;00m\n\u001B[0;32m     41\u001B[0m plt\u001B[39m.\u001B[39mimshow(flatfield[\u001B[39m0\u001B[39m], cmap\u001B[39m=\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mgray\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'pybasic' has no attribute 'basic'"
     ]
    }
   ],
   "source": [
    "img = fc.BasiCCorrection(img=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step of the preprocessing the data includes a couple of steps:\n",
    "\n",
    "- RESOLVE has missing data on the borders of two tiles, resulting in black lines on the border between tiles. This can split up cells, and thus influence the analysis. \n",
    "inpainting this black line circumvents this\n",
    "- Secondly, a tophatfilter can be added, by defining the size of the tophat filter. If the size of the tophatfilter is not defined, no tophatfilter is added. (I am not sure it actually still is a tophat filter). The goal of this function is to substract background noise, and make the borders of the nuclei cleaner, plus it will delete the occasional debris. If you take the size too small, smaller then the size of your nuclei, the function will create donuts, with black spots in the center of your cells.  If the size of the tophat filter is chosen too big, not enough background is substracted, so a tradeoff should be made. This might need some finetuning. More information can be found on https://biapol.github.io/blog/ryan_savill/03_background_subtraction/. For nuclei, 45-55 is a great starting point. Bigger for whole cells\n",
    "- Thirdly, this function enhances the contrast, meaning it makes the white and black more separate. It does this by using histogram equalization (CLAHE function). The amount of correction needed can be decided by adapting the contrast_clip value. If the image is already quite bright, 3.5 might be a good starting value. For dark images, you can go up to 10 or even more. \n",
    "\n",
    "The result of this function is a cleaned up images, that will give rise to better segmentation results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "crd = [3000, 6000, 5000, 9000] # a small subset of interest for visualization purposes.\n",
    "img = fc.preprocessImage(img=img, size_tophat=45, small_size_vis=crd, contrast_clip=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting the image\n",
    "\n",
    "For the segmentation, we make use of Cellpose, a deep learning network based on a UNET architecture. This is a great tool , because it segments both nuclei and whole cells. \n",
    "Multiple paramters need to be given as an inpute to the cellpose algorithm. \n",
    "- diameter includes an estimate of the diameter of a nucleus. If put to none, cellpose will do the estimation by himself, but this estimation might take longer than the actual segmentation. You can run the algorthim on a small piece (I[0:1000,0:1000] for example), to get an estimate. However, this estimate isn't always accurate. So check the quality at the end. IF you see all nuclei/cells are estimated too small, enlarge this parameter.\n",
    "- device defines the device you want to work on, if you only have cpu, you can skip this input parameter. If only having CPU, please tune the parameters on a small subset, and then make it to the big one. This might take a while. If that doesn't work, because of memory issues, you can always split up the image and paste it together, careful with mask numbering though.\n",
    "- flow_threshold: indicates something about the shape of the masks, if you increase it, more masks with less orund shapes will be accepted. Up to one:  I take it between 0.6 and 0.95\n",
    "- mask_threshold: indicates how many of the possible masks are kept. MAking it smaller (up to -6), will give you more masks, bigger is less masks. I take it between 0 and -6. Be careful, you can oversegment: always check the quality \n",
    "- min_size indicates the minimal size of a nucleus. \n",
    "- If segmenting whole cells instead of nuclei, set the parameter model_type to 'cyto'.\n",
    "- If using nuclei together with whole cells, put model_type to 'cyto', make sure your image is 3D and and that the first channel is you complete cell staining and you second one is the nucleus channel, put the parameter channel to np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "masks = fc.segmentation(img, device='cuda:4', mask_threshold=-4, flow_threshold=0.9, diameter=50, model_type='nuclei', small_size_vis=crd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the anndata object and allocating the transcripts \n",
    "\n",
    "In this steps multiple things happen:\n",
    "- shapes of the different cels in the mask are extracted and saved as a geopandas object. \n",
    "- The transcript file is read in  and all transcripts lying in the nuclei/cells are assigend to those nuclei/cells. i should find a new way to add my quality control here. All trancripts outside of the nuclei can be assigned surely to a cell and are thus discarded. Soing diffferently created very messy cells. \n",
    "- only cells with transcripts are retained, and the shapes of the cells are added to the anndata in adata.obsm['polygons']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#path_transcripts=\"/srv/scratch/lottep/data/PSB/Resolve data/Hormone dataset/pla1 section (mutant)/C1-2_results.txt\"\n",
    "adata = fc.create_adata_quick(path_Coordinates, img, masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot shapes is a funciton that can be used to visualize the cells (and subsets) on the image. by defining the column, the cells can be colored, as we will see later. Alpha defines the see-thoughness to the plotted masks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fc.plot_shapes(adata, crd=[2000, 4000, 2000, 4000], alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess adata \n",
    "\n",
    "This next code  preprocesses the adata object. \n",
    "- calculate QC metrics\n",
    "- filter cells with less then 10 gene counts and genes with less then 5 cells (adaptations possible by adapting the function)\n",
    "- Nuc_Size_norm: standard: perform normalization based on the size of the cell/nucleus, followed by scaling. if put to False, normal library size normalazation is performed (not recomendable, but you can check the difference).\n",
    "\n",
    "The last plot plot the size of the nucleus related to the counts. When working with whole cells, if there are some really big xcells with really low counts, probably they are not real cells, and you should filter based on max size. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata = fc.preprocessAdata(adata, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fc.plot_shapes(adata, column='total_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step you can filter cells base on their size: are you sure cells need to be bigger, or sure your cells can not be larger than X? \n",
    "\n",
    "You can delete them with this function by defining min_size and max_size. \n",
    "\n",
    "If necessary, this function inclused an extra filter step based on the estimated locations of the cells. The center of the cell is calculated as the mean location of the transcripts allocated to the cell, and as the middle of the shape.\n",
    "If the distance between both is really large, possibly the shape contains more than only the cell, and the cell is deleted. This isn't used for nucleus segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata = fc.filter_on_size(adata, min_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs the neighborhood analysis and the leidne clustering and the UMAP (standard scRNA stuff).\n",
    "\n",
    "You need to define 2 parameters:\n",
    "- the amount of PC's used: I normally choose something between 15-20 based on the plot\n",
    "- The amount of nieghbors used: normally I go for 35. Less neighbors means more spread, more means everything tighter (I think)\n",
    "\n",
    "It gives back the UMAP and marker gene list per cluster, that can be looked at for finding celltypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fc.preprocess3(adata, 17, 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reuse the plot_shapes function to actually plot a subfigure of our figure with the cells colored based on the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fc.plot_shapes(adata, column='leiden', crd=[2000, 4000, 3000, 5000], alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotating the cells \n",
    "\n",
    "In this part of the code we are going to annotate the cells based on marker gene lists. \n",
    "The marker geneslist should be a csv with the genes  in the rows and the celltypes in the columns.\n",
    "If a certain gene is a marker for a certain celltype, the value of the cell should be 1, otherwise it should be zero. \n",
    "This matrix is then used to annotate cells.  the path is the input for the function.\n",
    "\n",
    "All cells are scored for all celltypes. The higher the score the more likely a cell is belonging to a celltype. \n",
    "\n",
    "Sometimes some celltypes give way higher scores then others. This is the case in liver for hepatocytes. When you then want readable heatmaps, put the ROwNorm=True.\n",
    "This normalizes the scores within each cell. \n",
    "This will not influence which celltype a cell will get, but will influence the plots. \n",
    "However, for some downstream adaptations, you will not want this normalization. \n",
    "\n",
    "if not working with liver, you should use the pl.score_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_mg = '/srv/scratch/lottep/LiverMarkerGenes/markers_including_CD45neg.csv'\n",
    "mg_dict = fc.score_genes_liver(adata, path_mg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In liver, the marker genes for hepatocytes are everywhere, but way higher expressed in hepatocytes. This result in a high score for hepatocytes in cells that aren't hepatocytes. \n",
    "\n",
    "But those cells score much lower on being hepatocyte then the hepatocytes itselves. So they clearly aren't hepatocytes. \n",
    "In the following code we try to estimate how high of a hepatocyte score we actually need to assign a cell hepatocyte. \n",
    "In this case it is only necessary for hepatocytes. For melanoma more were necessary. \n",
    "\n",
    "We tried other techniques for annotation, such as Tangram too, but they seem to work even less good.\n",
    "So this is the best we have at the moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['Hepatocytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata.obs['Hep'] = (adata.obs['Hepatocytes']>5.6).astype(int)\n",
    "sc.pl.umap(adata, color=['Hep','Hepatocytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(adata.obs)):\n",
    "    if adata.obs['Hepatocytes'].iloc[i]<5.6:    \n",
    "        adata.obs['Hepatocytes'].iloc[i]=adata.obs['Hepatocytes'].iloc[i]/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code checks how well the clusters agree with the celltyping, it looks at every cluster and which celltypes are in there; You would want clean columns: one color per column.\n",
    "\n",
    "When not working with liver, put liver==False\n",
    "\n",
    "As not al celltypes can be distinguished based on 100 genes, I w-in liver mode combine celltypes. But a better idea would be to adapt the marker genes lists and only include the celltypes you are interested in. \n",
    "You can adapt this for your data too. \n",
    "\n",
    "Colors can also be adapted per cluster, but this is not an option yet, you would have to adapt the functions for that. \n",
    "\n",
    "Beautiful output plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata_p = fc.clustercleanliness(adata, img, celltypes=np.array(sorted(list(mg_dict.keys()))), crop_coord=crd, liver=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some adaptations to save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata.raw.var.index.names = ['genes']\n",
    "adata.var.index.names = ['genes']\n",
    "adata.obsm['spatial'] = adata.obsm['spatial'].rename({0: 'X', 1: 'Y'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use squidpy to see the enrichement between the different celltypes\n",
    "For more info, see squidpy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata, coord_type=\"generic\")\n",
    "sq.gr.nhood_enrichment(adata, cluster_key=\"maxScores\")\n",
    "sq.pl.nhood_enrichment(adata, cluster_key=\"maxScores\", method=\"ward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the objects\n",
    "\n",
    "As anndata can not save the shapes object, we have to save it separately.\n",
    "Normally I save the masks separately too, but I forgot that in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.obsm['polygons']['color']\n",
    "adata.obsm['polygons']['geometry'].to_file('/srv/scratch/lottep/RESOLVE/Pipeline_Results/adataFilesShort/adataAugust'+name_slide+'.geojson', driver='GeoJSON')\n",
    "del adata.obsm['polygons']['geometry']\n",
    "del adata.obsm['polygons']['border_color']\n",
    "adata.write('/srv/scratch/lottep/RESOLVE/Pipeline_Results/adataFilesShort/adataAugust'+name_slide+'.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('napari-spongepy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20420c8329320005ac547671395945f526df102965543c7e4408364b40628f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
